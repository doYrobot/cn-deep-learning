{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 图像分类\n",
    "\n",
    "在此项目中，你将对 [CIFAR-10 数据集](https://www.cs.toronto.edu/~kriz/cifar.html) 中的图片进行分类。该数据集包含飞机、猫狗和其他物体。你需要预处理这些图片，然后用所有样本训练一个卷积神经网络。图片需要标准化（normalized），标签需要采用 one-hot 编码。你需要应用所学的知识构建卷积的、最大池化（max pooling）、丢弃（dropout）和完全连接（fully connected）的层。最后，你需要在样本图片上看到神经网络的预测结果。\n",
    "\n",
    "\n",
    "## 获取数据\n",
    "\n",
    "请运行以下单元，以下载 [CIFAR-10 数据集（Python版）](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CIFAR-10 Dataset: 171MB [2:42:33, 17.5KB/s]                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索数据\n",
    "\n",
    "该数据集分成了几部分／批次（batches），以免你的机器在计算时内存不足。CIFAR-10 数据集包含 5 个部分，名称分别为 `data_batch_1`、`data_batch_2`，以此类推。每个部分都包含以下某个类别的标签和图片：\n",
    "\n",
    "* 飞机\n",
    "* 汽车\n",
    "* 鸟类\n",
    "* 猫\n",
    "* 鹿\n",
    "* 狗\n",
    "* 青蛙\n",
    "* 马\n",
    "* 船只\n",
    "* 卡车\n",
    "\n",
    "了解数据集也是对数据进行预测的必经步骤。你可以通过更改 `batch_id` 和 `sample_id` 探索下面的代码单元。`batch_id` 是数据集一个部分的 ID（1 到 5）。`sample_id` 是该部分中图片和标签对（label pair）的 ID。\n",
    "\n",
    "问问你自己：“可能的标签有哪些？”、“图片数据的值范围是多少？”、“标签是按顺序排列，还是随机排列的？”。思考类似的问题，有助于你预处理数据，并使预测结果更准确。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 6:\n",
      "Image - Min Value: 7 Max Value: 249\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 2 Name: bird\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9be0c8ae80>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 6\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现预处理函数\n",
    "\n",
    "### 标准化\n",
    "\n",
    "在下面的单元中，实现 `normalize` 函数，传入图片数据 `x`，并返回标准化 Numpy 数组。值应该在 0 到 1 的范围内（含 0 和 1）。返回对象应该和 `x` 的形状一样。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    \n",
    "    return x/255.0\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot 编码\n",
    "\n",
    "和之前的代码单元一样，你将为预处理实现一个函数。这次，你将实现 `one_hot_encode` 函数。输入，也就是 `x`，是一个标签列表。实现该函数，以返回为 one_hot 编码的 Numpy 数组的标签列表。标签的可能值为 0 到 9。每次调用 `one_hot_encode` 时，对于每个值，one_hot 编码函数应该返回相同的编码。确保将编码映射保存到该函数外面。\n",
    "\n",
    "提示：不要重复发明轮子。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    enc=OneHotEncoder()\n",
    "    enc.fit(np.array(range(10)).reshape(-1,1))\n",
    "    return enc.transform(np.array(x).reshape(-1,1)).toarray()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机化数据\n",
    "\n",
    "之前探索数据时，你已经了解到，样本的顺序是随机的。再随机化一次也不会有什么关系，但是对于这个数据集没有必要。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理所有数据并保存\n",
    "\n",
    "运行下方的代码单元，将预处理所有 CIFAR-10 数据，并保存到文件中。下面的代码还使用了 10% 的训练数据，用来验证。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "这是你的第一个检查点。如果你什么时候决定再回到该记事本，或需要重新启动该记事本，你可以从这里开始。预处理的数据已保存到本地。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建网络\n",
    "\n",
    "对于该神经网络，你需要将每层都构建为一个函数。你看到的大部分代码都位于函数外面。要更全面地测试你的代码，我们需要你将每层放入一个函数中。这样使我们能够提供更好的反馈，并使用我们的统一测试检测简单的错误，然后再提交项目。\n",
    "\n",
    ">**注意**：如果你觉得每周很难抽出足够的时间学习这门课程，我们为此项目提供了一个小捷径。对于接下来的几个问题，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 程序包中的类来构建每个层级，但是“卷积和最大池化层级”部分的层级除外。TF Layers 和 Keras 及 TFLearn 层级类似，因此很容易学会。\n",
    "\n",
    ">但是，如果你想充分利用这门课程，请尝试自己解决所有问题，不使用 TF Layers 程序包中的任何类。你依然可以使用其他程序包中的类，这些类和你在 TF Layers 中的类名称是一样的！例如，你可以使用 TF Neural Network 版本的 `conv2d` 类 [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)，而不是 TF Layers 版本的 `conv2d` 类 [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d)。\n",
    "\n",
    "我们开始吧！\n",
    "\n",
    "\n",
    "### 输入\n",
    "\n",
    "神经网络需要读取图片数据、one-hot 编码标签和丢弃保留概率（dropout keep probability）。请实现以下函数：\n",
    "\n",
    "* 实现 `neural_net_image_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `image_shape` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"x\" 命名\n",
    "* 实现 `neural_net_label_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `n_classes` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"y\" 命名\n",
    "* 实现 `neural_net_keep_prob_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)，用于丢弃保留概率\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"keep_prob\" 命名\n",
    "\n",
    "这些名称将在项目结束时，用于加载保存的模型。\n",
    "\n",
    "注意：TensorFlow 中的 `None` 表示形状可以是动态大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x = tf.placeholder(tf.float32,shape=[None,image_shape[0],image_shape[1],image_shape[2]],name=\"x\")\n",
    "    return x\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    y=tf.placeholder(tf.float32,shape=[None,n_classes],name=\"y\")\n",
    "    return y\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    keep_prob=tf.placeholder(tf.float32,name=\"keep_prob\")\n",
    "    return keep_prob\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积和最大池化层\n",
    "\n",
    "卷积层级适合处理图片。对于此代码单元，你应该实现函数 `conv2d_maxpool` 以便应用卷积然后进行最大池化：\n",
    "\n",
    "* 使用 `conv_ksize`、`conv_num_outputs` 和 `x_tensor` 的形状创建权重（weight）和偏置（bias）。\n",
    "* 使用权重和 `conv_strides` 对 `x_tensor` 应用卷积。\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "* 添加偏置\n",
    "* 向卷积中添加非线性激活（nonlinear activation）\n",
    "* 使用 `pool_ksize` 和 `pool_strides` 应用最大池化\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "\n",
    "**注意**：对于**此层**，**请勿使用** [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers)，但是仍然可以使用 TensorFlow 的 [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) 包。对于所有**其他层**，你依然可以使用快捷方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    weight=tf.Variable(tf.truncated_normal(shape=[conv_ksize[0],conv_ksize[1],\n",
    "                                            x_tensor.get_shape().as_list()[3],conv_num_outputs],stddev=0.1))\n",
    "    bias=tf.Variable(tf.zeros([conv_num_outputs]))\n",
    "    \n",
    "    conv_layer=tf.nn.conv2d(x_tensor,weight,strides=[1,conv_strides[0],conv_strides[1],1],padding='SAME')\n",
    "    conv_layer=tf.nn.bias_add(conv_layer,bias)\n",
    "    \n",
    "    conv_layer=tf.nn.relu(conv_layer)\n",
    "    \n",
    "    conv_layer=tf.nn.max_pool(\n",
    "        conv_layer,\n",
    "        ksize=[1,pool_ksize[0],pool_ksize[1],1],\n",
    "        strides=[1,pool_strides[0],pool_strides[1],1],\n",
    "        padding='SAME')\n",
    "    \n",
    "    return conv_layer \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扁平化层\n",
    "\n",
    "实现 `flatten` 函数，将 `x_tensor` 的维度从四维张量（4-D tensor）变成二维张量。输出应该是形状（*部分大小（Batch Size）*，*扁平化图片大小（Flattened Image Size）*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    flat_image_size=x_tensor.get_shape().as_list()[1]*x_tensor.get_shape().as_list()[2]*x_tensor.get_shape().as_list()[3]\n",
    "    x_tensor=tf.reshape(x_tensor,[-1,flat_image_size])\n",
    "    return x_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全连接层\n",
    "\n",
    "实现 `fully_conn` 函数，以向 `x_tensor` 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    weight=tf.Variable(tf.truncated_normal(shape=[x_tensor.get_shape().as_list()[1],num_outputs],stddev=0.1))\n",
    "    bias=tf.Variable(tf.zeros([num_outputs]))\n",
    "    \n",
    "    fully_conn_layer=tf.add(tf.matmul(x_tensor,weight),bias)\n",
    "    fully_conn_layer=tf.nn.relu(fully_conn_layer)\n",
    "    \n",
    "    return fully_conn_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出层\n",
    "\n",
    "实现 `output` 函数，向 x_tensor 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n",
    "\n",
    "**注意**：该层级不应应用 Activation、softmax 或交叉熵（cross entropy）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weight=tf.Variable(tf.truncated_normal(shape=[x_tensor.get_shape().as_list()[1],num_outputs],stddev=0.1))\n",
    "    bias=tf.Variable(tf.zeros([num_outputs]))\n",
    "    \n",
    "    output_layer=tf.add(tf.matmul(x_tensor,weight),bias)\n",
    "    return output_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建卷积模型\n",
    "\n",
    "实现函数 `conv_net`， 创建卷积神经网络模型。该函数传入一批图片 `x`，并输出对数（logits）。使用你在上方创建的层创建此模型：\n",
    "\n",
    "* 应用 1、2 或 3 个卷积和最大池化层（Convolution and Max Pool layers）\n",
    "* 应用一个扁平层（Flatten Layer）\n",
    "* 应用 1、2 或 3 个完全连接层（Fully Connected Layers）\n",
    "* 应用一个输出层（Output Layer）\n",
    "* 返回输出\n",
    "* 使用 `keep_prob` 向模型中的一个或多个层应用 [TensorFlow 的 Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    con2d_maxpool_layer=conv2d_maxpool(x,32,(5,5),(1,1),(2,2),(2,2))\n",
    "    con2d_maxpool_layer=conv2d_maxpool(con2d_maxpool_layer,64,(3,3),(1,1),(2,2),(2,2))\n",
    "    con2d_maxpool_layer=conv2d_maxpool(con2d_maxpool_layer,96,(3,3),(1,1),(2,2),(2,2))    \n",
    "    \n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    flatten_layer=flatten(con2d_maxpool_layer)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    fully_conn_layer=fully_conn(flatten_layer,256)\n",
    "    fully_conn_layer=tf.nn.dropout(fully_conn_layer,keep_prob)\n",
    "    \n",
    "    fully_conn_layer=fully_conn(fully_conn_layer,256)\n",
    "    fully_conn_layer=tf.nn.dropout(fully_conn_layer,keep_prob)    \n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    output_layer=output(fully_conn_layer,10)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return output_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练神经网络\n",
    "\n",
    "### 单次优化\n",
    "\n",
    "实现函数 `train_neural_network` 以进行单次优化（single optimization）。该优化应该使用 `optimizer` 优化 `session`，其中 `feed_dict` 具有以下参数：\n",
    "\n",
    "* `x` 表示图片输入\n",
    "* `y` 表示标签\n",
    "* `keep_prob` 表示丢弃的保留率\n",
    "\n",
    "每个部分都会调用该函数，所以 `tf.global_variables_initializer()` 已经被调用。\n",
    "\n",
    "注意：不需要返回任何内容。该函数只是用来优化神经网络。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "\n",
    "    session.run(optimizer,feed_dict={\n",
    "        x:feature_batch,\n",
    "        y:label_batch,\n",
    "        keep_prob:keep_probability})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 显示数据\n",
    "\n",
    "实现函数 `print_stats` 以输出损失和验证准确率。使用全局变量 `valid_features` 和 `valid_labels` 计算验证准确率。使用保留率 `1.0` 计算损失和验证准确率（loss and validation accuracy）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss=session.run(cost,feed_dict={\n",
    "        x:feature_batch,\n",
    "        y:label_batch,\n",
    "        keep_prob:1.})\n",
    "    valid_acc=session.run(accuracy,feed_dict={\n",
    "        x:valid_features,\n",
    "        y:valid_labels,\n",
    "        keep_prob:1.})\n",
    "        \n",
    "    print('Loss:{:>10.4f} Validation Accuracy:{:.6f}'.format(loss,valid_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数\n",
    "\n",
    "调试以下超参数：\n",
    "* 设置 `epochs` 表示神经网络停止学习或开始过拟合的迭代次数\n",
    "* 设置 `batch_size`，表示机器内存允许的部分最大体积。大部分人设为以下常见内存大小：\n",
    "\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* 设置 `keep_probability` 表示使用丢弃时保留节点的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 100\n",
    "batch_size = 512\n",
    "keep_probability = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在单个 CIFAR-10 部分上训练\n",
    "\n",
    "我们先用单个部分，而不是用所有的 CIFAR-10 批次训练神经网络。这样可以节省时间，并对模型进行迭代，以提高准确率。最终验证准确率达到 50% 或以上之后，在下一部分对所有数据运行模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:    2.2040 Validation Accuracy:0.220800\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:    1.9412 Validation Accuracy:0.317600\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:    1.7801 Validation Accuracy:0.372800\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:    1.6541 Validation Accuracy:0.412200\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:    1.5232 Validation Accuracy:0.445200\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:    1.4391 Validation Accuracy:0.463800\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:    1.3629 Validation Accuracy:0.485600\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:    1.2663 Validation Accuracy:0.499400\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:    1.1910 Validation Accuracy:0.515800\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:    1.1185 Validation Accuracy:0.528000\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:    1.0251 Validation Accuracy:0.526400\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:    0.9389 Validation Accuracy:0.547400\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:    0.8914 Validation Accuracy:0.545400\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:    0.8383 Validation Accuracy:0.550800\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:    0.7592 Validation Accuracy:0.558600\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:    0.7015 Validation Accuracy:0.561000\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:    0.6287 Validation Accuracy:0.576800\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:    0.6016 Validation Accuracy:0.562600\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:    0.5878 Validation Accuracy:0.556200\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:    0.5675 Validation Accuracy:0.576600\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完全训练模型\n",
    "\n",
    "现在，单个 CIFAR-10 部分的准确率已经不错了，试试所有五个部分吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:    2.0447 Validation Accuracy:0.285000\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:    1.7318 Validation Accuracy:0.386800\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:    1.4816 Validation Accuracy:0.415800\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:    1.4495 Validation Accuracy:0.438400\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:    1.4485 Validation Accuracy:0.455600\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:    1.4682 Validation Accuracy:0.481200\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:    1.3553 Validation Accuracy:0.489000\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:    1.1689 Validation Accuracy:0.506400\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:    1.2064 Validation Accuracy:0.522000\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:    1.2224 Validation Accuracy:0.533800\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:    1.2740 Validation Accuracy:0.532200\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:    1.1868 Validation Accuracy:0.561400\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:    0.9980 Validation Accuracy:0.561800\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:    1.0533 Validation Accuracy:0.562400\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:    1.0709 Validation Accuracy:0.570000\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:    1.1050 Validation Accuracy:0.581600\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:    1.0466 Validation Accuracy:0.589400\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:    0.9170 Validation Accuracy:0.598400\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:    0.9000 Validation Accuracy:0.599200\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:    0.9198 Validation Accuracy:0.607600\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:    0.9509 Validation Accuracy:0.611400\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:    0.8869 Validation Accuracy:0.616400\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:    0.8420 Validation Accuracy:0.617800\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:    0.7899 Validation Accuracy:0.625800\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:    0.8364 Validation Accuracy:0.628400\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:    0.8599 Validation Accuracy:0.627400\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:    0.8076 Validation Accuracy:0.626000\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:    0.7507 Validation Accuracy:0.637200\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:    0.7149 Validation Accuracy:0.636000\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:    0.7380 Validation Accuracy:0.648000\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:    0.7593 Validation Accuracy:0.647400\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:    0.7358 Validation Accuracy:0.643800\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:    0.6769 Validation Accuracy:0.645400\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:    0.6550 Validation Accuracy:0.649200\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:    0.6773 Validation Accuracy:0.652200\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:    0.6721 Validation Accuracy:0.667200\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:    0.6671 Validation Accuracy:0.662000\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:    0.6032 Validation Accuracy:0.661400\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:    0.5781 Validation Accuracy:0.664600\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:    0.6131 Validation Accuracy:0.658800\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:    0.6104 Validation Accuracy:0.667400\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:    0.5753 Validation Accuracy:0.664400\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:    0.5338 Validation Accuracy:0.664200\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:    0.5236 Validation Accuracy:0.667200\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:    0.5323 Validation Accuracy:0.675400\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:    0.5724 Validation Accuracy:0.668600\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:    0.5767 Validation Accuracy:0.655000\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:    0.4959 Validation Accuracy:0.680400\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:    0.4703 Validation Accuracy:0.674800\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:    0.4835 Validation Accuracy:0.672600\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:    0.5239 Validation Accuracy:0.674000\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss:    0.5537 Validation Accuracy:0.670600\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss:    0.4294 Validation Accuracy:0.687000\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss:    0.4102 Validation Accuracy:0.682200\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss:    0.4159 Validation Accuracy:0.682400\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:    0.4498 Validation Accuracy:0.679800\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss:    0.5083 Validation Accuracy:0.668800\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss:    0.3892 Validation Accuracy:0.685400\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss:    0.3997 Validation Accuracy:0.681200\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss:    0.3628 Validation Accuracy:0.699600\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:    0.4051 Validation Accuracy:0.690000\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss:    0.4680 Validation Accuracy:0.680200\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss:    0.3618 Validation Accuracy:0.688800\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss:    0.3475 Validation Accuracy:0.694800\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss:    0.3235 Validation Accuracy:0.695600\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:    0.3802 Validation Accuracy:0.683200\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss:    0.4283 Validation Accuracy:0.685000\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss:    0.3367 Validation Accuracy:0.688800\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss:    0.3413 Validation Accuracy:0.687400\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss:    0.2878 Validation Accuracy:0.701000\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:    0.3285 Validation Accuracy:0.697200\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss:    0.3777 Validation Accuracy:0.688800\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss:    0.2778 Validation Accuracy:0.697400\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss:    0.3171 Validation Accuracy:0.673400\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss:    0.2284 Validation Accuracy:0.709800\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:    0.3082 Validation Accuracy:0.700200\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss:    0.3628 Validation Accuracy:0.685600\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss:    0.2492 Validation Accuracy:0.704600\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:    0.2706 Validation Accuracy:0.685400\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss:    0.2146 Validation Accuracy:0.711600\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:    0.2717 Validation Accuracy:0.698000\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss:    0.3437 Validation Accuracy:0.683000\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss:    0.2326 Validation Accuracy:0.705800\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:    0.2513 Validation Accuracy:0.685000\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss:    0.2280 Validation Accuracy:0.705800\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:    0.2268 Validation Accuracy:0.704600\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss:    0.3047 Validation Accuracy:0.676600\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss:    0.2127 Validation Accuracy:0.706800\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:    0.2035 Validation Accuracy:0.687800\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss:    0.2061 Validation Accuracy:0.704000\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:    0.2066 Validation Accuracy:0.691200\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss:    0.2731 Validation Accuracy:0.687600\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:    0.2173 Validation Accuracy:0.687400\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:    0.2298 Validation Accuracy:0.676600\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:    0.2128 Validation Accuracy:0.679200\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:    0.2404 Validation Accuracy:0.676200\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:    0.2078 Validation Accuracy:0.702000\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:    0.1896 Validation Accuracy:0.695400\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:    0.2254 Validation Accuracy:0.690600\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:    0.1612 Validation Accuracy:0.701000\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:    0.1779 Validation Accuracy:0.703000\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss:    0.2015 Validation Accuracy:0.696600\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss:    0.1711 Validation Accuracy:0.696600\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss:    0.1698 Validation Accuracy:0.708600\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss:    0.1367 Validation Accuracy:0.693200\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:    0.1549 Validation Accuracy:0.699200\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss:    0.1593 Validation Accuracy:0.700800\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss:    0.1449 Validation Accuracy:0.707600\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss:    0.1389 Validation Accuracy:0.706600\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss:    0.1344 Validation Accuracy:0.695200\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:    0.1287 Validation Accuracy:0.695800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, CIFAR-10 Batch 2:  Loss:    0.1380 Validation Accuracy:0.693200\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss:    0.1228 Validation Accuracy:0.708600\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss:    0.1643 Validation Accuracy:0.691600\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss:    0.1197 Validation Accuracy:0.699600\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:    0.1555 Validation Accuracy:0.711800\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss:    0.1213 Validation Accuracy:0.702200\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss:    0.1040 Validation Accuracy:0.708000\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss:    0.1389 Validation Accuracy:0.692400\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss:    0.1061 Validation Accuracy:0.697000\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:    0.1339 Validation Accuracy:0.705400\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss:    0.1065 Validation Accuracy:0.699000\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss:    0.1040 Validation Accuracy:0.699600\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss:    0.1082 Validation Accuracy:0.698000\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss:    0.1154 Validation Accuracy:0.690600\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:    0.1155 Validation Accuracy:0.695800\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss:    0.0885 Validation Accuracy:0.704600\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss:    0.0905 Validation Accuracy:0.699600\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss:    0.0855 Validation Accuracy:0.701000\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss:    0.1295 Validation Accuracy:0.682400\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:    0.1041 Validation Accuracy:0.697200\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss:    0.0793 Validation Accuracy:0.696200\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss:    0.0827 Validation Accuracy:0.704400\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss:    0.0918 Validation Accuracy:0.691400\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss:    0.1014 Validation Accuracy:0.687400\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:    0.0964 Validation Accuracy:0.696000\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss:    0.0970 Validation Accuracy:0.698200\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss:    0.0673 Validation Accuracy:0.702000\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss:    0.0702 Validation Accuracy:0.696600\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss:    0.0587 Validation Accuracy:0.705000\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:    0.0719 Validation Accuracy:0.699800\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss:    0.0773 Validation Accuracy:0.698600\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss:    0.0617 Validation Accuracy:0.704000\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss:    0.0807 Validation Accuracy:0.692600\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss:    0.0843 Validation Accuracy:0.690000\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:    0.0857 Validation Accuracy:0.686600\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss:    0.0902 Validation Accuracy:0.688400\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss:    0.0707 Validation Accuracy:0.702800\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss:    0.0591 Validation Accuracy:0.701200\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss:    0.0706 Validation Accuracy:0.701200\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:    0.0665 Validation Accuracy:0.701000\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss:    0.0719 Validation Accuracy:0.689800\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss:    0.0548 Validation Accuracy:0.709000\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss:    0.0538 Validation Accuracy:0.713400\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss:    0.0425 Validation Accuracy:0.703800\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:    0.0656 Validation Accuracy:0.701200\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss:    0.0603 Validation Accuracy:0.699800\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss:    0.0465 Validation Accuracy:0.711800\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss:    0.0452 Validation Accuracy:0.703400\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss:    0.0465 Validation Accuracy:0.695200\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:    0.0511 Validation Accuracy:0.701000\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss:    0.0532 Validation Accuracy:0.697400\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss:    0.0324 Validation Accuracy:0.708400\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss:    0.0376 Validation Accuracy:0.706800\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss:    0.0416 Validation Accuracy:0.688400\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:    0.0579 Validation Accuracy:0.696400\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss:    0.0446 Validation Accuracy:0.697600\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss:    0.0386 Validation Accuracy:0.698000\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss:    0.0235 Validation Accuracy:0.707200\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss:    0.0301 Validation Accuracy:0.698400\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:    0.0339 Validation Accuracy:0.708600\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss:    0.0360 Validation Accuracy:0.696400\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss:    0.0223 Validation Accuracy:0.703400\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss:    0.0347 Validation Accuracy:0.712800\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss:    0.0421 Validation Accuracy:0.700400\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:    0.0373 Validation Accuracy:0.705200\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss:    0.0529 Validation Accuracy:0.691600\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss:    0.0275 Validation Accuracy:0.704400\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss:    0.0412 Validation Accuracy:0.703600\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss:    0.0348 Validation Accuracy:0.687000\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:    0.0256 Validation Accuracy:0.710600\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss:    0.0371 Validation Accuracy:0.695200\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss:    0.0266 Validation Accuracy:0.704800\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss:    0.0404 Validation Accuracy:0.701800\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss:    0.0617 Validation Accuracy:0.685400\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:    0.0409 Validation Accuracy:0.694200\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss:    0.0433 Validation Accuracy:0.689800\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss:    0.0231 Validation Accuracy:0.694000\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss:    0.0349 Validation Accuracy:0.707000\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss:    0.0475 Validation Accuracy:0.685200\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:    0.0440 Validation Accuracy:0.696800\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss:    0.0259 Validation Accuracy:0.691400\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss:    0.0270 Validation Accuracy:0.693200\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss:    0.0275 Validation Accuracy:0.692800\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss:    0.0142 Validation Accuracy:0.700200\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:    0.0298 Validation Accuracy:0.701000\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss:    0.0199 Validation Accuracy:0.710400\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss:    0.0200 Validation Accuracy:0.696600\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss:    0.0402 Validation Accuracy:0.696200\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss:    0.0182 Validation Accuracy:0.699600\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:    0.0366 Validation Accuracy:0.692600\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss:    0.0368 Validation Accuracy:0.699600\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss:    0.0162 Validation Accuracy:0.705200\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss:    0.0336 Validation Accuracy:0.697800\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss:    0.0278 Validation Accuracy:0.690000\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:    0.0262 Validation Accuracy:0.693600\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss:    0.0206 Validation Accuracy:0.701800\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss:    0.0179 Validation Accuracy:0.700000\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss:    0.0555 Validation Accuracy:0.692800\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss:    0.0334 Validation Accuracy:0.684400\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:    0.0302 Validation Accuracy:0.700000\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss:    0.0119 Validation Accuracy:0.704600\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss:    0.0141 Validation Accuracy:0.696200\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss:    0.0212 Validation Accuracy:0.700200\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss:    0.0355 Validation Accuracy:0.682000\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:    0.0253 Validation Accuracy:0.701400\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss:    0.0129 Validation Accuracy:0.705000\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss:    0.0113 Validation Accuracy:0.695600\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss:    0.0271 Validation Accuracy:0.700000\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss:    0.0147 Validation Accuracy:0.694000\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:    0.0184 Validation Accuracy:0.698200\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss:    0.0152 Validation Accuracy:0.703000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, CIFAR-10 Batch 3:  Loss:    0.0159 Validation Accuracy:0.695000\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss:    0.0138 Validation Accuracy:0.696200\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss:    0.0094 Validation Accuracy:0.700600\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:    0.0220 Validation Accuracy:0.705600\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss:    0.0174 Validation Accuracy:0.708000\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss:    0.0098 Validation Accuracy:0.700000\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss:    0.0128 Validation Accuracy:0.690200\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss:    0.0134 Validation Accuracy:0.697200\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:    0.0196 Validation Accuracy:0.705000\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss:    0.0140 Validation Accuracy:0.700200\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss:    0.0109 Validation Accuracy:0.704800\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss:    0.0140 Validation Accuracy:0.697000\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss:    0.0099 Validation Accuracy:0.701600\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:    0.0129 Validation Accuracy:0.701000\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss:    0.0163 Validation Accuracy:0.691200\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss:    0.0109 Validation Accuracy:0.705000\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss:    0.0137 Validation Accuracy:0.696200\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss:    0.0156 Validation Accuracy:0.699400\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:    0.0173 Validation Accuracy:0.702200\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss:    0.0160 Validation Accuracy:0.699200\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss:    0.0073 Validation Accuracy:0.697400\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss:    0.0143 Validation Accuracy:0.709600\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss:    0.0097 Validation Accuracy:0.693400\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:    0.0114 Validation Accuracy:0.706000\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss:    0.0197 Validation Accuracy:0.704000\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss:    0.0076 Validation Accuracy:0.704000\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss:    0.0125 Validation Accuracy:0.705000\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss:    0.0093 Validation Accuracy:0.704200\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:    0.0144 Validation Accuracy:0.711400\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss:    0.0113 Validation Accuracy:0.700600\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss:    0.0062 Validation Accuracy:0.709800\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss:    0.0106 Validation Accuracy:0.696400\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss:    0.0055 Validation Accuracy:0.707000\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:    0.0106 Validation Accuracy:0.709000\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss:    0.0137 Validation Accuracy:0.703400\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss:    0.0079 Validation Accuracy:0.705200\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss:    0.0140 Validation Accuracy:0.710600\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss:    0.0086 Validation Accuracy:0.695000\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:    0.0076 Validation Accuracy:0.721200\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss:    0.0111 Validation Accuracy:0.715000\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss:    0.0071 Validation Accuracy:0.695400\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss:    0.0099 Validation Accuracy:0.708400\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss:    0.0052 Validation Accuracy:0.713600\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:    0.0083 Validation Accuracy:0.710800\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss:    0.0126 Validation Accuracy:0.705400\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss:    0.0045 Validation Accuracy:0.712400\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss:    0.0131 Validation Accuracy:0.710400\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss:    0.0067 Validation Accuracy:0.696400\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:    0.0132 Validation Accuracy:0.712800\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss:    0.0147 Validation Accuracy:0.711600\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss:    0.0044 Validation Accuracy:0.709600\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss:    0.0091 Validation Accuracy:0.698000\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss:    0.0053 Validation Accuracy:0.705000\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:    0.0078 Validation Accuracy:0.708600\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss:    0.0153 Validation Accuracy:0.707200\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss:    0.0050 Validation Accuracy:0.715400\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss:    0.0071 Validation Accuracy:0.714000\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss:    0.0082 Validation Accuracy:0.696400\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:    0.0267 Validation Accuracy:0.701600\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss:    0.0065 Validation Accuracy:0.704000\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss:    0.0038 Validation Accuracy:0.711200\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss:    0.0068 Validation Accuracy:0.710400\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss:    0.0052 Validation Accuracy:0.702800\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:    0.0072 Validation Accuracy:0.708600\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss:    0.0069 Validation Accuracy:0.696000\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss:    0.0067 Validation Accuracy:0.713800\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss:    0.0113 Validation Accuracy:0.708200\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss:    0.0097 Validation Accuracy:0.682200\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:    0.0147 Validation Accuracy:0.697800\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss:    0.0065 Validation Accuracy:0.702000\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss:    0.0055 Validation Accuracy:0.710000\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss:    0.0159 Validation Accuracy:0.712200\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss:    0.0163 Validation Accuracy:0.689400\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:    0.0079 Validation Accuracy:0.703000\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss:    0.0089 Validation Accuracy:0.705800\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss:    0.0029 Validation Accuracy:0.710200\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss:    0.0051 Validation Accuracy:0.708200\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss:    0.0063 Validation Accuracy:0.683000\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:    0.0059 Validation Accuracy:0.707000\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss:    0.0146 Validation Accuracy:0.706200\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss:    0.0032 Validation Accuracy:0.706400\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss:    0.0110 Validation Accuracy:0.710200\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss:    0.0055 Validation Accuracy:0.703600\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:    0.0096 Validation Accuracy:0.703400\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss:    0.0091 Validation Accuracy:0.706200\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss:    0.0019 Validation Accuracy:0.712200\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss:    0.0072 Validation Accuracy:0.709000\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss:    0.0100 Validation Accuracy:0.695600\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:    0.0209 Validation Accuracy:0.697200\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss:    0.0057 Validation Accuracy:0.707200\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss:    0.0027 Validation Accuracy:0.712200\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss:    0.0070 Validation Accuracy:0.707200\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss:    0.0028 Validation Accuracy:0.694800\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:    0.0096 Validation Accuracy:0.700000\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss:    0.0059 Validation Accuracy:0.708000\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss:    0.0021 Validation Accuracy:0.716200\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss:    0.0087 Validation Accuracy:0.708400\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss:    0.0035 Validation Accuracy:0.695200\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:    0.0084 Validation Accuracy:0.703000\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss:    0.0056 Validation Accuracy:0.708600\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss:    0.0064 Validation Accuracy:0.711000\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss:    0.0054 Validation Accuracy:0.704000\n",
      "Epoch 65, CIFAR-10 Batch 5:  Loss:    0.0033 Validation Accuracy:0.705200\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:    0.0086 Validation Accuracy:0.704400\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss:    0.0050 Validation Accuracy:0.708200\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss:    0.0028 Validation Accuracy:0.710200\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss:    0.0050 Validation Accuracy:0.711200\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss:    0.0046 Validation Accuracy:0.700400\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:    0.0061 Validation Accuracy:0.711000\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss:    0.0058 Validation Accuracy:0.699200\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss:    0.0028 Validation Accuracy:0.710600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67, CIFAR-10 Batch 4:  Loss:    0.0111 Validation Accuracy:0.711800\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss:    0.0068 Validation Accuracy:0.702600\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:    0.0082 Validation Accuracy:0.699600\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss:    0.0085 Validation Accuracy:0.697000\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss:    0.0045 Validation Accuracy:0.709400\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss:    0.0066 Validation Accuracy:0.712400\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss:    0.0042 Validation Accuracy:0.711200\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:    0.0066 Validation Accuracy:0.701800\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss:    0.0165 Validation Accuracy:0.687800\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss:    0.0049 Validation Accuracy:0.702400\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss:    0.0032 Validation Accuracy:0.704000\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss:    0.0063 Validation Accuracy:0.698800\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:    0.0035 Validation Accuracy:0.708800\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss:    0.0070 Validation Accuracy:0.691200\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss:    0.0118 Validation Accuracy:0.697200\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss:    0.0050 Validation Accuracy:0.705200\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss:    0.0043 Validation Accuracy:0.701400\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:    0.0052 Validation Accuracy:0.701000\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss:    0.0028 Validation Accuracy:0.703400\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss:    0.0094 Validation Accuracy:0.694600\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss:    0.0061 Validation Accuracy:0.698000\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss:    0.0042 Validation Accuracy:0.711000\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:    0.0049 Validation Accuracy:0.708800\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss:    0.0048 Validation Accuracy:0.706600\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss:    0.0040 Validation Accuracy:0.710000\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss:    0.0023 Validation Accuracy:0.702600\n",
      "Epoch 72, CIFAR-10 Batch 5:  Loss:    0.0070 Validation Accuracy:0.701000\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:    0.0064 Validation Accuracy:0.715200\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss:    0.0038 Validation Accuracy:0.710600\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss:    0.0020 Validation Accuracy:0.707600\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss:    0.0072 Validation Accuracy:0.709000\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss:    0.0044 Validation Accuracy:0.706200\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:    0.0045 Validation Accuracy:0.709600\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss:    0.0063 Validation Accuracy:0.698200\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss:    0.0022 Validation Accuracy:0.719600\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss:    0.0046 Validation Accuracy:0.711800\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss:    0.0038 Validation Accuracy:0.701200\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:    0.0043 Validation Accuracy:0.705200\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss:    0.0028 Validation Accuracy:0.708800\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss:    0.0030 Validation Accuracy:0.708800\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss:    0.0043 Validation Accuracy:0.707600\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss:    0.0056 Validation Accuracy:0.700800\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:    0.0050 Validation Accuracy:0.712000\n",
      "Epoch 76, CIFAR-10 Batch 2:  Loss:    0.0030 Validation Accuracy:0.709800\n",
      "Epoch 76, CIFAR-10 Batch 3:  Loss:    0.0021 Validation Accuracy:0.714600\n",
      "Epoch 76, CIFAR-10 Batch 4:  Loss:    0.0051 Validation Accuracy:0.699200\n",
      "Epoch 76, CIFAR-10 Batch 5:  Loss:    0.0033 Validation Accuracy:0.706800\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:    0.0044 Validation Accuracy:0.702400\n",
      "Epoch 77, CIFAR-10 Batch 2:  Loss:    0.0033 Validation Accuracy:0.706000\n",
      "Epoch 77, CIFAR-10 Batch 3:  Loss:    0.0020 Validation Accuracy:0.710600\n",
      "Epoch 77, CIFAR-10 Batch 4:  Loss:    0.0133 Validation Accuracy:0.701000\n",
      "Epoch 77, CIFAR-10 Batch 5:  Loss:    0.0168 Validation Accuracy:0.693800\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:    0.0055 Validation Accuracy:0.701000\n",
      "Epoch 78, CIFAR-10 Batch 2:  Loss:    0.0021 Validation Accuracy:0.705400\n",
      "Epoch 78, CIFAR-10 Batch 3:  Loss:    0.0041 Validation Accuracy:0.707400\n",
      "Epoch 78, CIFAR-10 Batch 4:  Loss:    0.0026 Validation Accuracy:0.698400\n",
      "Epoch 78, CIFAR-10 Batch 5:  Loss:    0.0135 Validation Accuracy:0.697200\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:    0.0062 Validation Accuracy:0.691200\n",
      "Epoch 79, CIFAR-10 Batch 2:  Loss:    0.0058 Validation Accuracy:0.704600\n",
      "Epoch 79, CIFAR-10 Batch 3:  Loss:    0.0019 Validation Accuracy:0.711400\n",
      "Epoch 79, CIFAR-10 Batch 4:  Loss:    0.0118 Validation Accuracy:0.699400\n",
      "Epoch 79, CIFAR-10 Batch 5:  Loss:    0.0067 Validation Accuracy:0.698600\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:    0.0039 Validation Accuracy:0.698400\n",
      "Epoch 80, CIFAR-10 Batch 2:  Loss:    0.0055 Validation Accuracy:0.707200\n",
      "Epoch 80, CIFAR-10 Batch 3:  Loss:    0.0042 Validation Accuracy:0.704600\n",
      "Epoch 80, CIFAR-10 Batch 4:  Loss:    0.0051 Validation Accuracy:0.704200\n",
      "Epoch 80, CIFAR-10 Batch 5:  Loss:    0.0060 Validation Accuracy:0.706400\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:    0.0080 Validation Accuracy:0.698800\n",
      "Epoch 81, CIFAR-10 Batch 2:  Loss:    0.0069 Validation Accuracy:0.700800\n",
      "Epoch 81, CIFAR-10 Batch 3:  Loss:    0.0038 Validation Accuracy:0.705400\n",
      "Epoch 81, CIFAR-10 Batch 4:  Loss:    0.0030 Validation Accuracy:0.713600\n",
      "Epoch 81, CIFAR-10 Batch 5:  Loss:    0.0030 Validation Accuracy:0.712400\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:    0.0045 Validation Accuracy:0.705400\n",
      "Epoch 82, CIFAR-10 Batch 2:  Loss:    0.0146 Validation Accuracy:0.704600\n",
      "Epoch 82, CIFAR-10 Batch 3:  Loss:    0.0024 Validation Accuracy:0.709200\n",
      "Epoch 82, CIFAR-10 Batch 4:  Loss:    0.0059 Validation Accuracy:0.707200\n",
      "Epoch 82, CIFAR-10 Batch 5:  Loss:    0.0073 Validation Accuracy:0.709600\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:    0.0072 Validation Accuracy:0.700600\n",
      "Epoch 83, CIFAR-10 Batch 2:  Loss:    0.0139 Validation Accuracy:0.696400\n",
      "Epoch 83, CIFAR-10 Batch 3:  Loss:    0.0018 Validation Accuracy:0.711400\n",
      "Epoch 83, CIFAR-10 Batch 4:  Loss:    0.0070 Validation Accuracy:0.703600\n",
      "Epoch 83, CIFAR-10 Batch 5:  Loss:    0.0026 Validation Accuracy:0.706000\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:    0.0053 Validation Accuracy:0.709000\n",
      "Epoch 84, CIFAR-10 Batch 2:  Loss:    0.0094 Validation Accuracy:0.696000\n",
      "Epoch 84, CIFAR-10 Batch 3:  Loss:    0.0043 Validation Accuracy:0.703000\n",
      "Epoch 84, CIFAR-10 Batch 4:  Loss:    0.0081 Validation Accuracy:0.699800\n",
      "Epoch 84, CIFAR-10 Batch 5:  Loss:    0.0068 Validation Accuracy:0.711200\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:    0.0022 Validation Accuracy:0.709400\n",
      "Epoch 85, CIFAR-10 Batch 2:  Loss:    0.0026 Validation Accuracy:0.712400\n",
      "Epoch 85, CIFAR-10 Batch 3:  Loss:    0.0042 Validation Accuracy:0.705400\n",
      "Epoch 85, CIFAR-10 Batch 4:  Loss:    0.0035 Validation Accuracy:0.705800\n",
      "Epoch 85, CIFAR-10 Batch 5:  Loss:    0.0198 Validation Accuracy:0.707400\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:    0.0061 Validation Accuracy:0.709000\n",
      "Epoch 86, CIFAR-10 Batch 2:  Loss:    0.0027 Validation Accuracy:0.706200\n",
      "Epoch 86, CIFAR-10 Batch 3:  Loss:    0.0014 Validation Accuracy:0.705000\n",
      "Epoch 86, CIFAR-10 Batch 4:  Loss:    0.0018 Validation Accuracy:0.706000\n",
      "Epoch 86, CIFAR-10 Batch 5:  Loss:    0.0024 Validation Accuracy:0.704600\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:    0.0018 Validation Accuracy:0.699400\n",
      "Epoch 87, CIFAR-10 Batch 2:  Loss:    0.0020 Validation Accuracy:0.701600\n",
      "Epoch 87, CIFAR-10 Batch 3:  Loss:    0.0024 Validation Accuracy:0.702400\n",
      "Epoch 87, CIFAR-10 Batch 4:  Loss:    0.0026 Validation Accuracy:0.703400\n",
      "Epoch 87, CIFAR-10 Batch 5:  Loss:    0.0014 Validation Accuracy:0.710400\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:    0.0083 Validation Accuracy:0.702400\n",
      "Epoch 88, CIFAR-10 Batch 2:  Loss:    0.0031 Validation Accuracy:0.703400\n",
      "Epoch 88, CIFAR-10 Batch 3:  Loss:    0.0018 Validation Accuracy:0.708400\n",
      "Epoch 88, CIFAR-10 Batch 4:  Loss:    0.0027 Validation Accuracy:0.710400\n",
      "Epoch 88, CIFAR-10 Batch 5:  Loss:    0.0052 Validation Accuracy:0.713600\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:    0.0028 Validation Accuracy:0.701400\n",
      "Epoch 89, CIFAR-10 Batch 2:  Loss:    0.0019 Validation Accuracy:0.702000\n",
      "Epoch 89, CIFAR-10 Batch 3:  Loss:    0.0038 Validation Accuracy:0.707600\n",
      "Epoch 89, CIFAR-10 Batch 4:  Loss:    0.0054 Validation Accuracy:0.708600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89, CIFAR-10 Batch 5:  Loss:    0.0056 Validation Accuracy:0.714800\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:    0.0019 Validation Accuracy:0.709200\n",
      "Epoch 90, CIFAR-10 Batch 2:  Loss:    0.0026 Validation Accuracy:0.707400\n",
      "Epoch 90, CIFAR-10 Batch 3:  Loss:    0.0019 Validation Accuracy:0.702200\n",
      "Epoch 90, CIFAR-10 Batch 4:  Loss:    0.0078 Validation Accuracy:0.707200\n",
      "Epoch 90, CIFAR-10 Batch 5:  Loss:    0.0030 Validation Accuracy:0.713600\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:    0.0012 Validation Accuracy:0.702400\n",
      "Epoch 91, CIFAR-10 Batch 2:  Loss:    0.0011 Validation Accuracy:0.713800\n",
      "Epoch 91, CIFAR-10 Batch 3:  Loss:    0.0058 Validation Accuracy:0.706000\n",
      "Epoch 91, CIFAR-10 Batch 4:  Loss:    0.0018 Validation Accuracy:0.711000\n",
      "Epoch 91, CIFAR-10 Batch 5:  Loss:    0.0017 Validation Accuracy:0.709400\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:    0.0017 Validation Accuracy:0.706400\n",
      "Epoch 92, CIFAR-10 Batch 2:  Loss:    0.0056 Validation Accuracy:0.704600\n",
      "Epoch 92, CIFAR-10 Batch 3:  Loss:    0.0054 Validation Accuracy:0.703000\n",
      "Epoch 92, CIFAR-10 Batch 4:  Loss:    0.0026 Validation Accuracy:0.711400\n",
      "Epoch 92, CIFAR-10 Batch 5:  Loss:    0.0027 Validation Accuracy:0.716200\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:    0.0015 Validation Accuracy:0.703000\n",
      "Epoch 93, CIFAR-10 Batch 2:  Loss:    0.0020 Validation Accuracy:0.706400\n",
      "Epoch 93, CIFAR-10 Batch 3:  Loss:    0.0012 Validation Accuracy:0.708800\n",
      "Epoch 93, CIFAR-10 Batch 4:  Loss:    0.0034 Validation Accuracy:0.710000\n",
      "Epoch 93, CIFAR-10 Batch 5:  Loss:    0.0020 Validation Accuracy:0.719600\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:    0.0035 Validation Accuracy:0.704600\n",
      "Epoch 94, CIFAR-10 Batch 2:  Loss:    0.0032 Validation Accuracy:0.713000\n",
      "Epoch 94, CIFAR-10 Batch 3:  Loss:    0.0029 Validation Accuracy:0.715400\n",
      "Epoch 94, CIFAR-10 Batch 4:  Loss:    0.0010 Validation Accuracy:0.711600\n",
      "Epoch 94, CIFAR-10 Batch 5:  Loss:    0.0014 Validation Accuracy:0.711000\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:    0.0035 Validation Accuracy:0.708200\n",
      "Epoch 95, CIFAR-10 Batch 2:  Loss:    0.0018 Validation Accuracy:0.705200\n",
      "Epoch 95, CIFAR-10 Batch 3:  Loss:    0.0010 Validation Accuracy:0.705600\n",
      "Epoch 95, CIFAR-10 Batch 4:  Loss:    0.0011 Validation Accuracy:0.711000\n",
      "Epoch 95, CIFAR-10 Batch 5:  Loss:    0.0008 Validation Accuracy:0.719000\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:    0.0035 Validation Accuracy:0.708200\n",
      "Epoch 96, CIFAR-10 Batch 2:  Loss:    0.0040 Validation Accuracy:0.705000\n",
      "Epoch 96, CIFAR-10 Batch 3:  Loss:    0.0031 Validation Accuracy:0.702200\n",
      "Epoch 96, CIFAR-10 Batch 4:  Loss:    0.0015 Validation Accuracy:0.716200\n",
      "Epoch 96, CIFAR-10 Batch 5:  Loss:    0.0017 Validation Accuracy:0.715000\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:    0.0011 Validation Accuracy:0.701400\n",
      "Epoch 97, CIFAR-10 Batch 2:  Loss:    0.0015 Validation Accuracy:0.708000\n",
      "Epoch 97, CIFAR-10 Batch 3:  Loss:    0.0029 Validation Accuracy:0.705400\n",
      "Epoch 97, CIFAR-10 Batch 4:  Loss:    0.0019 Validation Accuracy:0.710600\n",
      "Epoch 97, CIFAR-10 Batch 5:  Loss:    0.0028 Validation Accuracy:0.715600\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:    0.0029 Validation Accuracy:0.707600\n",
      "Epoch 98, CIFAR-10 Batch 2:  Loss:    0.0075 Validation Accuracy:0.712800\n",
      "Epoch 98, CIFAR-10 Batch 3:  Loss:    0.0012 Validation Accuracy:0.715400\n",
      "Epoch 98, CIFAR-10 Batch 4:  Loss:    0.0024 Validation Accuracy:0.707200\n",
      "Epoch 98, CIFAR-10 Batch 5:  Loss:    0.0023 Validation Accuracy:0.711800\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:    0.0084 Validation Accuracy:0.712000\n",
      "Epoch 99, CIFAR-10 Batch 2:  Loss:    0.0010 Validation Accuracy:0.711800\n",
      "Epoch 99, CIFAR-10 Batch 3:  Loss:    0.0011 Validation Accuracy:0.712600\n",
      "Epoch 99, CIFAR-10 Batch 4:  Loss:    0.0009 Validation Accuracy:0.715200\n",
      "Epoch 99, CIFAR-10 Batch 5:  Loss:    0.0032 Validation Accuracy:0.705200\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:    0.0018 Validation Accuracy:0.703800\n",
      "Epoch 100, CIFAR-10 Batch 2:  Loss:    0.0031 Validation Accuracy:0.714600\n",
      "Epoch 100, CIFAR-10 Batch 3:  Loss:    0.0006 Validation Accuracy:0.713400\n",
      "Epoch 100, CIFAR-10 Batch 4:  Loss:    0.0026 Validation Accuracy:0.712200\n",
      "Epoch 100, CIFAR-10 Batch 5:  Loss:    0.0033 Validation Accuracy:0.718000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "模型已保存到本地。\n",
    "\n",
    "## 测试模型\n",
    "\n",
    "利用测试数据集测试你的模型。这将是最终的准确率。你的准确率应该高于 50%。如果没达到，请继续调整模型结构和参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.7114659935235977\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4lhEREREJNLiWEREREQk+n9aqs29G/1pHQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5c70ca1390>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为何准确率只有50-80%？\n",
    "\n",
    "你可能想问，为何准确率不能更高了？首先，对于简单的 CNN 网络来说，50% 已经不低了。纯粹猜测的准确率为10%。但是，你可能注意到有人的准确率[远远超过 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130)。这是因为我们还没有介绍所有的神经网络知识。我们还需要掌握一些其他技巧。\n",
    "\n",
    "## 提交项目\n",
    "\n",
    "提交项目时，确保先运行所有单元，然后再保存记事本。将 notebook 文件另存为“dlnd_image_classification.ipynb”，再在目录 \"File\" -> \"Download as\" 另存为 HTML 格式。请在提交的项目中包含 “helper.py” 和 “problem_unittests.py” 文件。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
